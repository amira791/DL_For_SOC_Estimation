{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "93f12aae-4199-4c09-85e7-6a5768de57ad",
   "metadata": {},
   "source": [
    "## Dev du DL Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cbdc0805-2d62-416d-8c61-99bcfb19610e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importation des bibs\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout, BatchNormalization, Flatten\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from pyswarm import pso\n",
    "from sklearn.metrics import mean_absolute_error, r2_score\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8b3b268b-d355-4821-8d80-f909fd22bf1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Chargement du preprocessed dataset ...\n"
     ]
    }
   ],
   "source": [
    "# Chargement du preprocessed dataset \n",
    "print(\" Chargement du preprocessed dataset ...\")\n",
    "file_path = r\"C:\\Users\\VECTUS\\DL_For_SOC_Estimation\\datasets\\preprocessed_dataset.csv\"\n",
    "df = pd.read_csv(file_path, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cae85e97-b201-4da2-bf16-85ae0c74d08a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Heure   Courant   Tension  Cellule_min  Cellule_max     Temp1  \\\n",
      "0       0.000  1.761051  1.241628     1.233194     1.215263  0.913307   \n",
      "1       0.809  1.761051  1.241628     1.247615     1.230126  0.913307   \n",
      "2       1.650  1.761051  1.241628     1.233194     1.230126  0.913307   \n",
      "3       2.480  1.756236  1.241628     1.233194     1.230126  0.913307   \n",
      "4       3.256  1.751421  1.241628     1.247615     1.244989  0.913307   \n",
      "...       ...       ...       ...          ...          ...       ...   \n",
      "1262  291.010 -0.352752 -0.305522    -0.295502    -0.285891 -0.583666   \n",
      "1263  291.789 -0.347937 -0.305522    -0.309923    -0.271028 -0.583666   \n",
      "1264  292.633 -0.352752 -0.305522    -0.295502    -0.300754 -0.583666   \n",
      "1265  293.414 -0.352752 -0.305522    -0.281080    -0.285891 -0.583666   \n",
      "1266  294.195 -0.352752 -0.305522    -0.281080    -0.285891 -0.583666   \n",
      "\n",
      "         Temp4   SOC  \n",
      "0     1.194604  79.4  \n",
      "1     1.194604  79.4  \n",
      "2     1.194604  79.4  \n",
      "3     1.194604  79.4  \n",
      "4     1.194604  79.4  \n",
      "...        ...   ...  \n",
      "1262 -0.592365  75.8  \n",
      "1263 -0.592365  75.8  \n",
      "1264 -0.592365  75.8  \n",
      "1265 -0.592365  75.8  \n",
      "1266 -0.592365  75.8  \n",
      "\n",
      "[1267 rows x 8 columns]\n"
     ]
    }
   ],
   "source": [
    "print (df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "62444a12-f71e-4938-91ec-cb1c92991446",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Définition des features et de la cible\n",
    "features = [\"Courant\", \"Tension\", \"Cellule_min\", \"Cellule_max\", \"Temp1\", \"Temp4\"]\n",
    "target = \"SOC\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "efe31435-468d-4196-9685-76ec16c52539",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Courant   Tension  Cellule_min  Cellule_max  Temp1         Temp4\n",
      "0     0.996845  0.578947     0.565657     0.546392    0.0  2.220446e-16\n",
      "1     0.996845  0.578947     0.575758     0.556701    0.0  2.220446e-16\n",
      "2     0.996845  0.578947     0.565657     0.556701    0.0  2.220446e-16\n",
      "3     0.993691  0.578947     0.565657     0.556701    0.0  2.220446e-16\n",
      "4     0.990536  0.578947     0.575758     0.567010    0.0  2.220446e-16\n",
      "...        ...       ...          ...          ...    ...           ...\n",
      "1262 -0.388013 -0.473684    -0.505051    -0.494845   -1.0 -1.000000e+00\n",
      "1263 -0.384858 -0.473684    -0.515152    -0.484536   -1.0 -1.000000e+00\n",
      "1264 -0.388013 -0.473684    -0.505051    -0.505155   -1.0 -1.000000e+00\n",
      "1265 -0.388013 -0.473684    -0.494949    -0.494845   -1.0 -1.000000e+00\n",
      "1266 -0.388013 -0.473684    -0.494949    -0.494845   -1.0 -1.000000e+00\n",
      "\n",
      "[1267 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Normalisation des features et de la target\n",
    "feature_scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "target_scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "\n",
    "df[features] = feature_scaler.fit_transform(df[features])\n",
    "df[target] = target_scaler.fit_transform(df[[target]])\n",
    "print (df[features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "48c759d1-4131-4671-b11a-85180ecbff14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PRÉPARATION DES SÉQUENCES \n",
    "def create_sequences(data, features, target, seq_length):\n",
    "    X, y = [], []\n",
    "    for i in range(len(data) - seq_length):\n",
    "        X.append(data[features].iloc[i:i+seq_length].values)\n",
    "        y.append(data[target].iloc[i+seq_length])\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "seq_length = 15\n",
    "X, y = create_sequences(df, features, target, seq_length)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)\n",
    "X_train_split, X_val, y_train_split, y_val = train_test_split(X_train, y_train, test_size=0.2, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d2d528ae-48a7-4f83-b286-4e51d578d3dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  OPTIMISATION PSO \n",
    "from tensorflow.keras.layers import Attention, MultiHeadAttention\n",
    "\n",
    "def build_lstm(params, input_shape):\n",
    "    units1, units2, dropout_rate, learning_rate = params\n",
    "    \n",
    "    inputs = tf.keras.Input(shape=input_shape)\n",
    "    \n",
    "    # Première couche LSTM avec return_sequences=True pour l'attention\n",
    "    lstm1 = LSTM(int(units1), return_sequences=True)(inputs)\n",
    "    lstm1 = BatchNormalization()(lstm1)\n",
    "    lstm1 = Dropout(dropout_rate)(lstm1)\n",
    "    \n",
    "    # Mécanisme d'attention\n",
    "    attention = MultiHeadAttention(num_heads=2, key_dim=int(units1//2))(lstm1, lstm1)\n",
    "    lstm1 = tf.keras.layers.Add()([lstm1, attention])\n",
    "    lstm1 = LayerNormalization()(lstm1)\n",
    "    \n",
    "    # Deuxième couche LSTM\n",
    "    lstm2 = LSTM(int(units2))(lstm1)\n",
    "    lstm2 = BatchNormalization()(lstm2)\n",
    "    lstm2 = Dropout(dropout_rate)(lstm2)\n",
    "    \n",
    "    # Couches denses avec initialisation He\n",
    "    dense = Dense(64, activation='relu', kernel_initializer='he_normal')(lstm2)\n",
    "    dense = Dense(32, activation='relu', kernel_initializer='he_normal')(dense)\n",
    "    outputs = Dense(1, activation='linear')(dense)\n",
    "    \n",
    "    model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
    "    \n",
    "    optimizer = tf.keras.optimizers.Adam(\n",
    "        learning_rate=learning_rate,\n",
    "        beta_1=0.9,\n",
    "        beta_2=0.999,\n",
    "        epsilon=1e-07\n",
    "    )\n",
    "    \n",
    "    model.compile(optimizer=optimizer, loss='huber', metrics=['mae'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "354f68ee-7fbd-4d86-bad6-bb7a9a98f53a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonction d'évaluation optimisée\n",
    "def create_evaluator(X_train, y_train, X_val, y_val):\n",
    "    def evaluator(params):\n",
    "        model = build_lstm(params, (X_train.shape[1], X_train.shape[2]))\n",
    "        \n",
    "        callbacks = [\n",
    "            tf.keras.callbacks.EarlyStopping(\n",
    "                monitor='val_loss',\n",
    "                patience=5,\n",
    "                restore_best_weights=True\n",
    "            )\n",
    "        ]\n",
    "        \n",
    "        history = model.fit(\n",
    "            X_train, y_train,\n",
    "            epochs=20,\n",
    "            batch_size=32,\n",
    "            validation_data=(X_val, y_val),\n",
    "            verbose=1,\n",
    "            callbacks=callbacks\n",
    "        )\n",
    "        \n",
    "        return min(history.history['val_loss']) + 0.2 * min(history.history['val_mae'])\n",
    "    \n",
    "    return evaluator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0df45baf-2e19-471a-8280-c12d726212c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Début de l'optimisation PSO ===\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "evaluate_params() missing 4 required positional arguments: 'X_train', 'y_train', 'X_val', and 'y_val'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[28], line 8\u001b[0m\n\u001b[0;32m      5\u001b[0m lb_global \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m64\u001b[39m, \u001b[38;5;241m32\u001b[39m, \u001b[38;5;241m0.15\u001b[39m, \u001b[38;5;241m0.0005\u001b[39m]  \u001b[38;5;66;03m# Bornes inférieures\u001b[39;00m\n\u001b[0;32m      6\u001b[0m ub_global \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m384\u001b[39m, \u001b[38;5;241m192\u001b[39m, \u001b[38;5;241m0.3\u001b[39m, \u001b[38;5;241m0.005\u001b[39m]   \u001b[38;5;66;03m# Bornes supérieures\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m best_params_global, _ \u001b[38;5;241m=\u001b[39m \u001b[43mpso\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mevaluate_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlb_global\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43mub_global\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43mswarmsize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m15\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmaxiter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m15\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     14\u001b[0m \u001b[43m)\u001b[49m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# Deuxième passe (recherche locale)\u001b[39;00m\n\u001b[0;32m     16\u001b[0m lb_local \u001b[38;5;241m=\u001b[39m [x \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m0.8\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m best_params_global]  \u001b[38;5;66;03m# -20%\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pyswarm\\pso.py:111\u001b[0m, in \u001b[0;36mpso\u001b[1;34m(func, lb, ub, ieqcons, f_ieqcons, args, kwargs, swarmsize, omega, phip, phig, maxiter, minstep, minfunc, debug)\u001b[0m\n\u001b[0;32m    108\u001b[0m p[i, :] \u001b[38;5;241m=\u001b[39m x[i, :]\n\u001b[0;32m    110\u001b[0m \u001b[38;5;66;03m# Calculate the objective's value at the current particle's\u001b[39;00m\n\u001b[1;32m--> 111\u001b[0m fp[i] \u001b[38;5;241m=\u001b[39m \u001b[43mobj\u001b[49m\u001b[43m(\u001b[49m\u001b[43mp\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    113\u001b[0m \u001b[38;5;66;03m# At the start, there may not be any feasible starting point, so just\u001b[39;00m\n\u001b[0;32m    114\u001b[0m \u001b[38;5;66;03m# give it a temporary \"best\" point since it's likely to change\u001b[39;00m\n\u001b[0;32m    115\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m i\u001b[38;5;241m==\u001b[39m\u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pyswarm\\pso.py:74\u001b[0m, in \u001b[0;36mpso.<locals>.<lambda>\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m     71\u001b[0m vlow \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39mvhigh\n\u001b[0;32m     73\u001b[0m \u001b[38;5;66;03m# Check for constraint function(s) #########################################\u001b[39;00m\n\u001b[1;32m---> 74\u001b[0m obj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     75\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m f_ieqcons \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     76\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(ieqcons):\n",
      "\u001b[1;31mTypeError\u001b[0m: evaluate_params() missing 4 required positional arguments: 'X_train', 'y_train', 'X_val', and 'y_val'"
     ]
    }
   ],
   "source": [
    "# Optimisation PSO en deux passes\n",
    "# Création de la fonction d'évaluation avec les données encapsulées\n",
    "evaluator = create_evaluator(X_train_split, y_train_split, X_val, y_val)\n",
    "\n",
    "# Optimisation PSO\n",
    "print(\"\\n=== Début de l'optimisation PSO ===\")\n",
    "\n",
    "# Première passe (globale)\n",
    "lb_global = [64, 32, 0.15, 0.0005]\n",
    "ub_global = [384, 192, 0.3, 0.005]\n",
    "\n",
    "best_params_global, best_loss_global = pso(\n",
    "    evaluator,  # Utilisation de la fonction encapsulée\n",
    "    lb_global,\n",
    "    ub_global,\n",
    "    swarmsize=10,\n",
    "    maxiter=10\n",
    ")\n",
    "\n",
    "# Deuxième passe (locale)\n",
    "lb_local = [x * 0.8 for x in best_params_global]\n",
    "ub_local = [x * 1.2 for x in best_params_global]\n",
    "\n",
    "best_params, best_loss = pso(\n",
    "    evaluator,\n",
    "    lb_local,\n",
    "    ub_local,\n",
    "    swarmsize=10,\n",
    "    maxiter=10\n",
    ")\n",
    "\n",
    "print(f\"\\nMeilleurs paramètres trouvés : {best_params}\")\n",
    "print(f\"Meilleure loss validation : {best_loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87bee72b-b91f-4c3a-a1c0-09a73f4748b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ENTRAÎNEMENT DU MODÈLE FINAL ===\n",
    "final_model = build_lstm(best_params, (X_train.shape[1], X_train.shape[2]))\n",
    "history = final_model.fit(X_train, y_train, epochs=50, batch_size=32, validation_data=(X_test, y_test), callbacks=[\n",
    "    tf.keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True),\n",
    "    tf.keras.callbacks.ReduceLROnPlateau(factor=0.1, patience=5)\n",
    "], verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d78d9196-538e-46fb-8d18-253e68c047e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === 6. ÉVALUATION ===\n",
    "y_pred = final_model.predict(X_test)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print(\"\\n=== Résultats ===\")\n",
    "print(f\"MAE : {mae:.4f}\")\n",
    "print(f\"R² : {r2:.4f}\")\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(y_test, label='Valeurs réelles')\n",
    "plt.plot(y_pred, label='Prédictions', alpha=0.7)\n",
    "plt.title(\"Prédiction du SOC\")\n",
    "plt.xlabel(\"Cycle\")\n",
    "plt.ylabel(\"SOC (%)\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "78851822-2127-48f2-828e-099dc13fbb22",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'scaler' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m \u001b[43mscaler\u001b[49m\u001b[38;5;241m.\u001b[39minverse_transform(y_pred\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m))\n\u001b[0;32m      2\u001b[0m y_test \u001b[38;5;241m=\u001b[39m scaler\u001b[38;5;241m.\u001b[39minverse_transform(y_test\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'scaler' is not defined"
     ]
    }
   ],
   "source": [
    "y_pred = scaler.inverse_transform(y_pred.reshape(-1, 1))\n",
    "y_test = scaler.inverse_transform(y_test.reshape(-1, 1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a13cf1c9-b626-4686-91b3-bb68f6b07054",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "amira",
   "language": "python",
   "name": "amira"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
